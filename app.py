"""
Gemini å›¾ç‰‡ç”Ÿæˆå™¨ - Flask åç«¯æœåŠ¡
åŸºäº Vertex AI API è°ƒç”¨ gemini-3-pro-image-preview æ¨¡å‹
å¢å¼ºç‰ˆï¼šæ”¯æŒå›¾ç‰‡å°ºå¯¸ã€Google Search Groundingã€å›¾åƒç¼–è¾‘ã€æ€è€ƒè¿‡ç¨‹å¯è§†åŒ–
"""

import os
import json
import uuid
import base64
from datetime import datetime
from io import BytesIO
from pathlib import Path

from flask import Flask, render_template, request, jsonify, Response, send_from_directory
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

app = Flask(__name__)
app.config['MAX_CONTENT_LENGTH'] = 50 * 1024 * 1024  # 50MB ä¸Šä¼ é™åˆ¶

# æ•°æ®ç›®å½•é…ç½®
BASE_DIR = Path(__file__).parent
DATA_DIR = BASE_DIR / "data"
UPLOADS_DIR = DATA_DIR / "uploads"
GENERATED_DIR = DATA_DIR / "generated"
CONVERSATIONS_FILE = DATA_DIR / "conversations.json"

# ç¡®ä¿ç›®å½•å­˜åœ¨
for dir_path in [DATA_DIR, UPLOADS_DIR, GENERATED_DIR]:
    dir_path.mkdir(parents=True, exist_ok=True)

# åˆå§‹åŒ–å¯¹è¯å­˜å‚¨
if not CONVERSATIONS_FILE.exists():
    CONVERSATIONS_FILE.write_text("[]", encoding="utf-8")

# Vertex AI å®¢æˆ·ç«¯ (å»¶è¿Ÿåˆå§‹åŒ–)
_client = None

# æœ‰æ•ˆçš„å›¾ç‰‡æ¯”ä¾‹é€‰é¡¹
VALID_ASPECT_RATIOS = ["1:1", "3:2", "2:3", "3:4", "4:3", "4:5", "5:4", "9:16", "16:9", "21:9"]
# æœ‰æ•ˆçš„å›¾ç‰‡å°ºå¯¸é€‰é¡¹
VALID_IMAGE_SIZES = ["1K", "2K", "4K"]


def get_vertex_client():
    """è·å– Vertex AI å®¢æˆ·ç«¯ (å»¶è¿Ÿåˆå§‹åŒ–)"""
    global _client
    if _client is None:
        try:
            from google import genai
            
            # ä» key.json è¯»å–é¡¹ç›® ID
            key_file = BASE_DIR / "key.json"
            if key_file.exists():
                import json
                key_data = json.loads(key_file.read_text(encoding="utf-8"))
                default_project = key_data.get("project_id", "")
                # è®¾ç½®å‡­è¯ç¯å¢ƒå˜é‡
                os.environ.setdefault("GOOGLE_APPLICATION_CREDENTIALS", str(key_file))
            else:
                default_project = ""
            
            project_id = os.getenv("GOOGLE_CLOUD_PROJECT", os.getenv("PROJECT_ID", default_project))
            location = os.getenv("GOOGLE_CLOUD_LOCATION", "global")
            
            if not project_id:
                raise ValueError("è¯·è®¾ç½® GOOGLE_CLOUD_PROJECT ç¯å¢ƒå˜é‡æˆ–æä¾› key.json")
            
            _client = genai.Client(
                vertexai=True,
                project=project_id,
                location=location
            )
            print(f"âœ… Vertex AI å®¢æˆ·ç«¯å·²åˆå§‹åŒ– (é¡¹ç›®: {project_id}, åŒºåŸŸ: {location})")
        except Exception as e:
            print(f"âŒ Vertex AI å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    return _client


def load_conversations():
    """åŠ è½½å¯¹è¯å†å²"""
    try:
        return json.loads(CONVERSATIONS_FILE.read_text(encoding="utf-8"))
    except:
        return []


def save_conversations(conversations):
    """ä¿å­˜å¯¹è¯å†å²"""
    CONVERSATIONS_FILE.write_text(
        json.dumps(conversations, ensure_ascii=False, indent=2),
        encoding="utf-8"
    )


def save_image_from_bytes(image_bytes: bytes, prefix: str = "") -> tuple:
    """ä¿å­˜å›¾ç‰‡å¹¶è¿”å›æ–‡ä»¶åå’Œbase64"""
    from PIL import Image
    
    img = Image.open(BytesIO(image_bytes))
    filename = f"{prefix}{uuid.uuid4()}.png"
    output_path = GENERATED_DIR / filename
    img.save(output_path)
    
    img_base64 = base64.b64encode(image_bytes).decode("utf-8")
    return filename, img_base64


def parse_grounding_metadata(grounding_metadata) -> dict:
    """è§£æ grounding å…ƒæ•°æ®"""
    result = {
        "sources": [],
        "search_queries": [],
    }
    
    if not grounding_metadata:
        return result
    
    # è§£ææœç´¢æŸ¥è¯¢
    if grounding_metadata.web_search_queries:
        result["search_queries"] = list(grounding_metadata.web_search_queries)
    
    # è§£æ grounding chunks
    if grounding_metadata.grounding_chunks:
        for chunk in grounding_metadata.grounding_chunks:
            context = chunk.web or chunk.retrieved_context
            if context:
                source = {
                    "title": getattr(context, "title", "Source") or "Source",
                    "uri": getattr(context, "uri", "") or ""
                }
                # è½¬æ¢ GCS URI ä¸º HTTPS
                if source["uri"].startswith("gs://"):
                    source["uri"] = source["uri"].replace(
                        "gs://", "https://storage.googleapis.com/", 1
                    )
                result["sources"].append(source)
    
    return result


# ============ è·¯ç”± ============

@app.route("/")
def index():
    """ä¸»é¡µ"""
    return render_template("index.html")


@app.route("/api/config")
def get_config():
    """è·å–å¯ç”¨é…ç½®é€‰é¡¹"""
    return jsonify({
        "aspect_ratios": VALID_ASPECT_RATIOS,
        "image_sizes": VALID_IMAGE_SIZES,
        "modes": ["standard", "search", "edit"]
    })


@app.route("/api/conversations", methods=["GET"])
def get_conversations():
    """è·å–æ‰€æœ‰å¯¹è¯åˆ—è¡¨ï¼ˆåŒ…å«å®Œæ•´æ¶ˆæ¯ï¼‰"""
    conversations = load_conversations()
    return jsonify(conversations)


@app.route("/api/conversations/<conv_id>", methods=["GET"])
def get_conversation(conv_id):
    """è·å–å•ä¸ªå¯¹è¯è¯¦æƒ…"""
    conversations = load_conversations()
    for c in conversations:
        if c["id"] == conv_id:
            return jsonify(c)
    return jsonify({"error": "å¯¹è¯ä¸å­˜åœ¨"}), 404


@app.route("/api/conversations", methods=["POST"])
def create_conversation():
    """åˆ›å»ºæ–°å¯¹è¯"""
    conversations = load_conversations()
    new_conv = {
        "id": str(uuid.uuid4()),
        "title": "æ–°å¯¹è¯",
        "messages": [],
        "created_at": datetime.now().isoformat(),
        "updated_at": datetime.now().isoformat()
    }
    conversations.insert(0, new_conv)
    save_conversations(conversations)
    return jsonify(new_conv)


@app.route("/api/conversations/<conv_id>", methods=["PUT"])
def update_conversation(conv_id):
    """æ›´æ–°å¯¹è¯"""
    data = request.json
    conversations = load_conversations()
    for c in conversations:
        if c["id"] == conv_id:
            if "title" in data:
                c["title"] = data["title"]
            if "messages" in data:
                c["messages"] = data["messages"]
            c["updated_at"] = datetime.now().isoformat()
            save_conversations(conversations)
            return jsonify(c)
    return jsonify({"error": "å¯¹è¯ä¸å­˜åœ¨"}), 404


@app.route("/api/conversations/<conv_id>", methods=["DELETE"])
def delete_conversation(conv_id):
    """åˆ é™¤å¯¹è¯"""
    conversations = load_conversations()
    conversations = [c for c in conversations if c["id"] != conv_id]
    save_conversations(conversations)
    return jsonify({"success": True})


@app.route("/api/conversations/<conv_id>/messages/<int:msg_index>", methods=["DELETE"])
def delete_message(conv_id, msg_index):
    """åˆ é™¤å¯¹è¯ä¸­çš„å•æ¡æ¶ˆæ¯"""
    conversations = load_conversations()
    for c in conversations:
        if c["id"] == conv_id:
            messages = c.get("messages", [])
            if 0 <= msg_index < len(messages):
                messages.pop(msg_index)
                c["messages"] = messages
                c["updated_at"] = datetime.now().isoformat()
                save_conversations(conversations)
                return jsonify({"success": True, "messages": messages})
            else:
                return jsonify({"error": "æ¶ˆæ¯ç´¢å¼•è¶…å‡ºèŒƒå›´"}), 400
    return jsonify({"error": "å¯¹è¯ä¸å­˜åœ¨"}), 404


@app.route("/api/upload", methods=["POST"])
def upload_file():
    """ä¸Šä¼ æ–‡ä»¶"""
    if "file" not in request.files:
        return jsonify({"error": "æ²¡æœ‰æ–‡ä»¶"}), 400
    
    file = request.files["file"]
    if file.filename == "":
        return jsonify({"error": "æ–‡ä»¶åä¸ºç©º"}), 400
    
    ext = Path(file.filename).suffix.lower()
    filename = f"{uuid.uuid4()}{ext}"
    filepath = UPLOADS_DIR / filename
    
    file.save(filepath)
    
    mime_map = {
        ".jpg": "image/jpeg",
        ".jpeg": "image/jpeg",
        ".png": "image/png",
        ".gif": "image/gif",
        ".webp": "image/webp",
        ".pdf": "application/pdf"
    }
    mime_type = mime_map.get(ext, "application/octet-stream")
    
    return jsonify({
        "filename": filename,
        "original_name": file.filename,
        "mime_type": mime_type,
        "path": f"/uploads/{filename}"
    })


@app.route("/uploads/<filename>")
def serve_upload(filename):
    """æä¾›ä¸Šä¼ æ–‡ä»¶è®¿é—®"""
    return send_from_directory(UPLOADS_DIR, filename)


@app.route("/generated/<filename>")
def serve_generated(filename):
    """æä¾›ç”Ÿæˆå›¾ç‰‡è®¿é—®"""
    return send_from_directory(GENERATED_DIR, filename)


def build_history_contents(history: list, types_module):
    """æ„å»ºå†å²æ¶ˆæ¯å†…å®¹"""
    contents = []
    for msg in history:
        role = "user" if msg.get("role") == "user" else "model"
        parts = []
        
        # æ·»åŠ æ–‡æœ¬
        if msg.get("text"):
            parts.append(msg["text"])
        
        # æ·»åŠ å›¾ç‰‡ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        if msg.get("image"):
            image_path = msg["image"]
            # å¤„ç†è·¯å¾„
            if image_path.startswith("/generated/"):
                filename = image_path.replace("/generated/", "")
                filepath = GENERATED_DIR / filename
            elif image_path.startswith("/uploads/"):
                filename = image_path.replace("/uploads/", "")
                filepath = UPLOADS_DIR / filename
            else:
                filepath = None
            
            if filepath and filepath.exists():
                with open(filepath, "rb") as fp:
                    img_data = fp.read()
                parts.append(types_module.Part.from_bytes(
                    data=img_data,
                    mime_type="image/png"
                ))
        
        if parts:
            contents.append(types_module.Content(role=role, parts=parts))
    
    return contents


@app.route("/api/generate", methods=["POST"])
def generate_image():
    """ç”Ÿæˆå›¾ç‰‡ (SSE æµå¼å“åº”) - æ ‡å‡†æ¨¡å¼"""
    data = request.json
    prompt = data.get("prompt", "")
    files = data.get("files", [])
    aspect_ratio = str(data.get("aspect_ratio", "1:1")).strip() or "1:1"
    image_size = str(data.get("image_size", "1K")).strip() or "1K"
    include_text = data.get("include_text", True)  # æ˜¯å¦åŒæ—¶è¿”å›æ–‡æœ¬
    history = data.get("history", [])  # å†å²æ¶ˆæ¯
    
    # éªŒè¯å‚æ•°
    if aspect_ratio not in VALID_ASPECT_RATIOS:
        aspect_ratio = "1:1"
    if image_size not in VALID_IMAGE_SIZES:
        image_size = "1K"
    
    if not prompt and not files:
        return jsonify({"error": "è¯·è¾“å…¥æç¤ºè¯æˆ–ä¸Šä¼ æ–‡ä»¶"}), 400
    
    def generate():
        try:
            from google.genai import types
            
            client = get_vertex_client()
            
            # æ„å»ºè¯·æ±‚å†…å®¹
            # å¦‚æœæœ‰å†å²æ¶ˆæ¯ï¼Œä½¿ç”¨å¤šè½®å¯¹è¯æ ¼å¼
            if history:
                contents = build_history_contents(history, types)
                # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
                current_parts = []
                if prompt:
                    current_parts.append(prompt)
                for f in files:
                    filepath = find_image_file(f["filename"])
                    if filepath and filepath.exists():
                        with open(filepath, "rb") as fp:
                            file_data = fp.read()
                        current_parts.append(types.Part.from_bytes(
                            data=file_data,
                            mime_type=f["mime_type"]
                        ))
                if current_parts:
                    contents.append(types.Content(role="user", parts=current_parts))
                print(f"ğŸ“œ ä½¿ç”¨ä¸Šä¸‹æ–‡è®°å¿†ï¼Œå…± {len(contents)} è½®æ¶ˆæ¯")
            else:
                # å•è½®å¯¹è¯
                parts = []
                if prompt:
                    parts.append(prompt)
                
                for f in files:
                    filepath = UPLOADS_DIR / f["filename"]
                    if filepath.exists():
                        with open(filepath, "rb") as fp:
                            file_data = fp.read()
                        parts.append(types.Part.from_bytes(
                            data=file_data,
                            mime_type=f["mime_type"]
                        ))
                contents = parts
            
            # é…ç½®å“åº”æ¨¡æ€
            response_modalities = ["IMAGE"]
            if include_text:
                response_modalities = ["TEXT", "IMAGE"]
            
            config = types.GenerateContentConfig(
                response_modalities=response_modalities,
                image_config=types.ImageConfig(
                    aspect_ratio=aspect_ratio,
                    image_size=image_size
                )
            )
            
            yield f"data: {json.dumps({'type': 'start', 'message': 'å¼€å§‹ç”Ÿæˆ...'})}\n\n"
            
            print(f"ğŸ›°ï¸ è¯·æ±‚æ¨¡å‹: gemini-3-pro-image-preview, aspect_ratio={aspect_ratio}, image_size={image_size}")
            response_stream = client.models.generate_content_stream(
                model="gemini-3-pro-image-preview",
                contents=contents,
                config=config
            )
            
            final_image_bytes = None
            all_text = ""
            thinking_text = ""
            thinking_images = []
            
            for chunk in response_stream:
                # å¤„ç†å„ä¸ª part
                if chunk.candidates and chunk.candidates[0].content and chunk.candidates[0].content.parts:
                    for part in chunk.candidates[0].content.parts:
                        # æ£€æŸ¥æ˜¯å¦æ˜¯æ€è€ƒè¿‡ç¨‹
                        if hasattr(part, 'thought') and part.thought:
                            if part.text:
                                thinking_text += part.text
                                yield f"data: {json.dumps({'type': 'thinking', 'text': part.text})}\n\n"
                            elif part.inline_data:
                                # æ€è€ƒè¿‡ç¨‹ä¸­çš„å›¾ç‰‡
                                img_data = part.inline_data.data
                                filename, img_b64 = save_image_from_bytes(img_data, "thought_")
                                thinking_images.append({
                                    "filename": filename,
                                    "path": f"/generated/{filename}"
                                })
                                yield f"data: {json.dumps({'type': 'thinking_image', 'filename': filename, 'path': f'/generated/{filename}', 'base64': img_b64})}\n\n"
                        else:
                            # æ™®é€šå†…å®¹
                            if part.text:
                                all_text += part.text
                                yield f"data: {json.dumps({'type': 'text', 'text': part.text})}\n\n"
                            elif part.inline_data:
                                final_image_bytes = part.inline_data.data
                                print(f"ğŸ–¼ï¸ æ”¶åˆ°å›¾ç‰‡åˆ†ç‰‡: {len(final_image_bytes)} bytes")
            
            if final_image_bytes:
                filename, img_base64 = save_image_from_bytes(final_image_bytes)
                
                yield f"data: {json.dumps({'type': 'image', 'filename': filename, 'path': f'/generated/{filename}', 'base64': img_base64})}\n\n"
                yield f"data: {json.dumps({'type': 'done', 'message': 'ç”Ÿæˆå®Œæˆ!', 'full_text': all_text, 'thinking': thinking_text, 'thinking_images': thinking_images})}\n\n"
            else:
                yield f"data: {json.dumps({'type': 'error', 'message': 'æœªç”Ÿæˆå›¾ç‰‡ï¼Œå¯èƒ½è¢«å®‰å…¨ç­–ç•¥æ‹¦æˆª'})}\n\n"
                
        except Exception as e:
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"
    
    return Response(generate(), mimetype="text/event-stream")


@app.route("/api/generate-with-search", methods=["POST"])
def generate_with_search():
    """Google Search å¢å¼ºç”Ÿæˆ (SSE æµå¼å“åº”)"""
    data = request.json
    prompt = data.get("prompt", "")
    aspect_ratio = str(data.get("aspect_ratio", "1:1")).strip() or "1:1"
    image_size = str(data.get("image_size", "1K")).strip() or "1K"
    
    if aspect_ratio not in VALID_ASPECT_RATIOS:
        aspect_ratio = "1:1"
    if image_size not in VALID_IMAGE_SIZES:
        image_size = "1K"
    
    if not prompt:
        return jsonify({"error": "è¯·è¾“å…¥æç¤ºè¯"}), 400
    
    def generate():
        try:
            from google.genai import types
            
            client = get_vertex_client()
            
            # åˆ›å»º Google Search å·¥å…·
            google_search = types.Tool(google_search=types.GoogleSearch())
            
            config = types.GenerateContentConfig(
                response_modalities=["TEXT", "IMAGE"],
                image_config=types.ImageConfig(
                    aspect_ratio=aspect_ratio,
                    image_size=image_size
                ),
                tools=[google_search]
            )
            
            yield f"data: {json.dumps({'type': 'start', 'message': 'æ­£åœ¨æœç´¢å¹¶ç”Ÿæˆ...'})}\n\n"
            
            print(f"ğŸ” æœç´¢å¢å¼ºç”Ÿæˆ: {prompt[:50]}...")
            
            # ä½¿ç”¨éæµå¼è°ƒç”¨ä»¥è·å–å®Œæ•´çš„ grounding metadata
            response = client.models.generate_content(
                model="gemini-3-pro-image-preview",
                contents=prompt,
                config=config
            )
            
            # æ£€æŸ¥å“åº”çŠ¶æ€
            if response.candidates[0].finish_reason != types.FinishReason.STOP:
                reason = response.candidates[0].finish_reason
                yield f"data: {json.dumps({'type': 'error', 'message': f'ç”Ÿæˆè¢«ä¸­æ–­: {reason}'})}\n\n"
                return
            
            final_image_bytes = None
            all_text = ""
            thinking_text = ""
            thinking_images = []
            
            for part in response.candidates[0].content.parts:
                if hasattr(part, 'thought') and part.thought:
                    if part.text:
                        thinking_text += part.text
                        yield f"data: {json.dumps({'type': 'thinking', 'text': part.text})}\n\n"
                    elif part.inline_data:
                        img_data = part.inline_data.data
                        filename, img_b64 = save_image_from_bytes(img_data, "thought_")
                        thinking_images.append({"filename": filename, "path": f"/generated/{filename}"})
                        yield f"data: {json.dumps({'type': 'thinking_image', 'filename': filename, 'path': f'/generated/{filename}', 'base64': img_b64})}\n\n"
                else:
                    if part.text:
                        all_text += part.text
                        yield f"data: {json.dumps({'type': 'text', 'text': part.text})}\n\n"
                    elif part.inline_data:
                        final_image_bytes = part.inline_data.data
            
            # è§£æ grounding æ•°æ®
            grounding_data = {}
            if response.candidates[0].grounding_metadata:
                grounding_data = parse_grounding_metadata(response.candidates[0].grounding_metadata)
                yield f"data: {json.dumps({'type': 'grounding', 'data': grounding_data})}\n\n"
            
            if final_image_bytes:
                filename, img_base64 = save_image_from_bytes(final_image_bytes)
                
                yield f"data: {json.dumps({'type': 'image', 'filename': filename, 'path': f'/generated/{filename}', 'base64': img_base64})}\n\n"
                yield f"data: {json.dumps({'type': 'done', 'message': 'æœç´¢å¢å¼ºç”Ÿæˆå®Œæˆ!', 'full_text': all_text, 'thinking': thinking_text, 'thinking_images': thinking_images, 'grounding': grounding_data})}\n\n"
            else:
                yield f"data: {json.dumps({'type': 'error', 'message': 'æœªç”Ÿæˆå›¾ç‰‡'})}\n\n"
                
        except Exception as e:
            import traceback
            traceback.print_exc()
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"
    
    return Response(generate(), mimetype="text/event-stream")


def find_image_file(filename: str):
    """åœ¨ uploads å’Œ generated ç›®å½•ä¸­æŸ¥æ‰¾å›¾ç‰‡æ–‡ä»¶"""
    # å…ˆåœ¨ uploads ç›®å½•æŸ¥æ‰¾
    filepath = UPLOADS_DIR / filename
    if filepath.exists():
        return filepath
    
    # å†åœ¨ generated ç›®å½•æŸ¥æ‰¾
    filepath = GENERATED_DIR / filename
    if filepath.exists():
        return filepath
    
    # å¤„ç†å¯èƒ½å¸¦æœ‰ edit_ æˆ–å…¶ä»–å‰ç¼€çš„æ–‡ä»¶å
    # ä¹Ÿå¤„ç†è·¯å¾„ä¸­å¯èƒ½åŒ…å«çš„ç›®å½•å‰ç¼€
    clean_filename = filename.split('/')[-1]  # ç§»é™¤å¯èƒ½çš„è·¯å¾„å‰ç¼€
    
    filepath = UPLOADS_DIR / clean_filename
    if filepath.exists():
        return filepath
    
    filepath = GENERATED_DIR / clean_filename
    if filepath.exists():
        return filepath
    
    return None


@app.route("/api/edit-image", methods=["POST"])
def edit_image():
    """å›¾åƒç¼–è¾‘ (SSE æµå¼å“åº”) - æ”¯æŒæœ¬åœ°åŒ–/ç¿»è¯‘/å±€éƒ¨ä¿®æ”¹"""
    data = request.json
    prompt = data.get("prompt", "")
    files = data.get("files", [])
    aspect_ratio = str(data.get("aspect_ratio", "")).strip()  # ç¼–è¾‘æ¨¡å¼å¯èƒ½ä¿æŒåŸæ¯”ä¾‹
    image_size = str(data.get("image_size", "1K")).strip() or "1K"
    edit_type = data.get("edit_type", "general")  # general, translate, style
    
    if image_size not in VALID_IMAGE_SIZES:
        image_size = "1K"
    
    if not files:
        return jsonify({"error": "è¯·ä¸Šä¼ è¦ç¼–è¾‘çš„å›¾ç‰‡"}), 400
    
    if not prompt:
        return jsonify({"error": "è¯·è¾“å…¥ç¼–è¾‘æŒ‡ä»¤"}), 400
    
    def generate():
        try:
            from google.genai import types
            
            client = get_vertex_client()
            
            # æ„å»ºå†…å®¹ - å›¾ç‰‡åœ¨å‰ï¼ŒæŒ‡ä»¤åœ¨å
            contents = []
            
            for f in files:
                filepath = find_image_file(f["filename"])
                if filepath and filepath.exists():
                    with open(filepath, "rb") as fp:
                        file_data = fp.read()
                    contents.append(types.Part.from_bytes(
                        data=file_data,
                        mime_type=f["mime_type"]
                    ))
                    print(f"ğŸ“ å·²åŠ è½½å›¾ç‰‡: {filepath}")
            
            # æ ¹æ®ç¼–è¾‘ç±»å‹æ„å»ºæç¤º
            if edit_type == "translate":
                full_prompt = f"è¯·å°†å›¾ç‰‡ä¸­çš„æ–‡å­—ç¿»è¯‘/è½¬æ¢ä¸ºä»¥ä¸‹è¯­è¨€ï¼Œä¿æŒå›¾ç‰‡å…¶ä»–å…ƒç´ ä¸å˜ï¼š{prompt}"
            elif edit_type == "style":
                full_prompt = f"è¯·æŒ‰ç…§ä»¥ä¸‹é£æ ¼ä¿®æ”¹å›¾ç‰‡ï¼Œä¿æŒä¸»è¦å†…å®¹ä¸å˜ï¼š{prompt}"
            else:
                full_prompt = prompt
            
            contents.append(full_prompt)
            
            # é…ç½®
            image_config_params = {"image_size": image_size}
            if aspect_ratio and aspect_ratio in VALID_ASPECT_RATIOS:
                image_config_params["aspect_ratio"] = aspect_ratio
            
            config = types.GenerateContentConfig(
                response_modalities=["TEXT", "IMAGE"],
                image_config=types.ImageConfig(**image_config_params)
            )
            
            yield f"data: {json.dumps({'type': 'start', 'message': 'æ­£åœ¨ç¼–è¾‘å›¾ç‰‡...'})}\n\n"
            
            print(f"âœï¸ å›¾åƒç¼–è¾‘: {full_prompt[:50]}...")
            response_stream = client.models.generate_content_stream(
                model="gemini-3-pro-image-preview",
                contents=contents,
                config=config
            )
            
            final_image_bytes = None
            all_text = ""
            thinking_text = ""
            thinking_images = []
            
            for chunk in response_stream:
                if chunk.candidates and chunk.candidates[0].content and chunk.candidates[0].content.parts:
                    for part in chunk.candidates[0].content.parts:
                        if hasattr(part, 'thought') and part.thought:
                            if part.text:
                                thinking_text += part.text
                                yield f"data: {json.dumps({'type': 'thinking', 'text': part.text})}\n\n"
                            elif part.inline_data:
                                img_data = part.inline_data.data
                                filename, img_b64 = save_image_from_bytes(img_data, "thought_")
                                thinking_images.append({"filename": filename, "path": f"/generated/{filename}"})
                                yield f"data: {json.dumps({'type': 'thinking_image', 'filename': filename, 'path': f'/generated/{filename}', 'base64': img_b64})}\n\n"
                        else:
                            if part.text:
                                all_text += part.text
                                yield f"data: {json.dumps({'type': 'text', 'text': part.text})}\n\n"
                            elif part.inline_data:
                                final_image_bytes = part.inline_data.data
                                print(f"ğŸ–¼ï¸ ç¼–è¾‘ç»“æœ: {len(final_image_bytes)} bytes")
            
            if final_image_bytes:
                filename, img_base64 = save_image_from_bytes(final_image_bytes, "edit_")
                
                yield f"data: {json.dumps({'type': 'image', 'filename': filename, 'path': f'/generated/{filename}', 'base64': img_base64})}\n\n"
                yield f"data: {json.dumps({'type': 'done', 'message': 'ç¼–è¾‘å®Œæˆ!', 'full_text': all_text, 'thinking': thinking_text, 'thinking_images': thinking_images})}\n\n"
            else:
                yield f"data: {json.dumps({'type': 'error', 'message': 'ç¼–è¾‘å¤±è´¥ï¼Œæœªç”Ÿæˆå›¾ç‰‡'})}\n\n"
                
        except Exception as e:
            import traceback
            traceback.print_exc()
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"
    
    return Response(generate(), mimetype="text/event-stream")


if __name__ == "__main__":
    print("=" * 50)
    print("ğŸ¨ Gemini å›¾ç‰‡ç”Ÿæˆå™¨ - å¢å¼ºç‰ˆ")
    print("=" * 50)
    print(f"ğŸ“ æ•°æ®ç›®å½•: {DATA_DIR}")
    print(f"ğŸ“ ä¸Šä¼ ç›®å½•: {UPLOADS_DIR}")
    print(f"ğŸ“ ç”Ÿæˆç›®å½•: {GENERATED_DIR}")
    print("=" * 50)
    print("æ”¯æŒçš„åŠŸèƒ½:")
    print("  âœ… æ ‡å‡†å›¾ç‰‡ç”Ÿæˆ (TEXT + IMAGE)")
    print("  âœ… Google Search æœç´¢å¢å¼ºç”Ÿæˆ")
    print("  âœ… å›¾åƒç¼–è¾‘ (ç¿»è¯‘/æœ¬åœ°åŒ–/é£æ ¼)")
    print("  âœ… å›¾ç‰‡å°ºå¯¸é€‰æ‹© (1K/2K/4K)")
    print("  âœ… å®Œæ•´æ¯”ä¾‹æ”¯æŒ (1:1 åˆ° 21:9)")
    print("  âœ… æ€è€ƒè¿‡ç¨‹å¯è§†åŒ–")
    print("=" * 50)
    print("è¯·ç¡®ä¿å·²è®¾ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡:")
    print("  - GOOGLE_APPLICATION_CREDENTIALS (æœåŠ¡è´¦å·å¯†é’¥è·¯å¾„)")
    print("  - GOOGLE_CLOUD_PROJECT (GCP é¡¹ç›® ID)")
    print("  - GOOGLE_CLOUD_LOCATION (å¯é€‰ï¼Œé»˜è®¤ global)")
    print("=" * 50)
    
    app.run(host="0.0.0.0", port=5000, debug=True)
